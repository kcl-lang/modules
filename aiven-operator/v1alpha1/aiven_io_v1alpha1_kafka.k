"""
This file was generated by the KCL auto-gen tool. DO NOT EDIT.
Editing this file might prove futile when you re-run the KCL auto-gen generate command.
"""
import regex
import k8s.apimachinery.pkg.apis.meta.v1


schema Kafka:
    """
    Kafka is the Schema for the kafkas API

    Attributes
    ----------
    apiVersion : str, default is "aiven.io/v1alpha1", required
        APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources
    kind : str, default is "Kafka", required
        Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
    metadata : v1.ObjectMeta, default is Undefined, optional
        metadata
    spec : AivenIoV1alpha1KafkaSpec, default is Undefined, optional
        spec
    status : AivenIoV1alpha1KafkaStatus, default is Undefined, optional
        status
    """


    apiVersion: "aiven.io/v1alpha1" = "aiven.io/v1alpha1"

    kind: "Kafka" = "Kafka"

    metadata?: v1.ObjectMeta

    spec?: AivenIoV1alpha1KafkaSpec

    status?: AivenIoV1alpha1KafkaStatus


schema AivenIoV1alpha1KafkaSpec:
    """
    KafkaSpec defines the desired state of Kafka

    Attributes
    ----------
    authSecretRef : AivenIoV1alpha1KafkaSpecAuthSecretRef, default is Undefined, optional
        auth secret ref
    cloudName : str, default is Undefined, optional
        Cloud the service runs in.
    connInfoSecretTarget : AivenIoV1alpha1KafkaSpecConnInfoSecretTarget, default is Undefined, optional
        conn info secret target
    disk_space : str, default is Undefined, optional
        The disk space of the service, possible values depend on the service type, the cloud provider and the project. Reducing will result in the service re-balancing.
    karapace : bool, default is Undefined, optional
        Switch the service to use Karapace for schema registry and REST proxy
    maintenanceWindowDow : str, default is Undefined, optional
        Day of week when maintenance operations should be performed. One monday, tuesday, wednesday, etc.
    maintenanceWindowTime : str, default is Undefined, optional
        Time of day when maintenance operations should be performed. UTC time in HH:mm:ss format.
    plan : str, default is Undefined, required
        Subscription plan.
    project : str, default is Undefined, required
        Target project.
    projectVPCRef : AivenIoV1alpha1KafkaSpecProjectVPCRef, default is Undefined, optional
        project v p c ref
    projectVpcId : str, default is Undefined, optional
        Identifier of the VPC the service should be in, if any.
    serviceIntegrations : [AivenIoV1alpha1KafkaSpecServiceIntegrationsItems0], default is Undefined, optional
        Service integrations to specify when creating a service. Not applied after initial service creation
    tags : {str:str}, default is Undefined, optional
        Tags are key-value pairs that allow you to categorize services.
    terminationProtection : bool, default is Undefined, optional
        Prevent service from being deleted. It is recommended to have this enabled for all services.
    userConfig : AivenIoV1alpha1KafkaSpecUserConfig, default is Undefined, optional
        user config
    """


    authSecretRef?: AivenIoV1alpha1KafkaSpecAuthSecretRef

    cloudName?: str

    connInfoSecretTarget?: AivenIoV1alpha1KafkaSpecConnInfoSecretTarget

    disk_space?: str

    karapace?: bool

    maintenanceWindowDow?: "monday" | "tuesday" | "wednesday" | "thursday" | "friday" | "saturday" | "sunday"

    maintenanceWindowTime?: str

    plan: str

    project: str

    projectVPCRef?: AivenIoV1alpha1KafkaSpecProjectVPCRef

    projectVpcId?: str

    serviceIntegrations?: [AivenIoV1alpha1KafkaSpecServiceIntegrationsItems0]

    tags?: {str:str}

    terminationProtection?: bool

    userConfig?: AivenIoV1alpha1KafkaSpecUserConfig


    check:
        len(cloudName) <= 256
        len(maintenanceWindowTime) <= 8
        len(plan) <= 128
        len(project) <= 63
        len(projectVpcId) <= 36
        len(serviceIntegrations) <= 1


schema AivenIoV1alpha1KafkaSpecAuthSecretRef:
    """
    Authentication reference to Aiven token in a secret

    Attributes
    ----------
    key : str, default is Undefined, required
        key
    name : str, default is Undefined, required
        name
    """


    key: str

    name: str


    check:
        len(key) >= 1
        len(name) >= 1


schema AivenIoV1alpha1KafkaSpecConnInfoSecretTarget:
    """
    Information regarding secret creation. 
     Exposed keys: `KAFKA_HOST`, `KAFKA_PORT`, `KAFKA_USERNAME`, `KAFKA_PASSWORD`, `KAFKA_ACCESS_CERT`, `KAFKA_ACCESS_KEY`

    Attributes
    ----------
    annotations : {str:str}, default is Undefined, optional
        Annotations added to the secret
    labels : {str:str}, default is Undefined, optional
        Labels added to the secret
    name : str, default is Undefined, required
        Name of the secret resource to be created. By default, is equal to the resource name
    prefix : str, default is Undefined, optional
        Prefix for the secret's keys. Added "as is" without any transformations. By default, is equal to the kind name in uppercase + underscore, e.g. `KAFKA_`, `REDIS_`, etc.
    """


    annotations?: {str:str}

    labels?: {str:str}

    name: str

    prefix?: str


schema AivenIoV1alpha1KafkaSpecProjectVPCRef:
    """
    ProjectVPCRef reference to ProjectVPC resource to use its ID as ProjectVPCID automatically

    Attributes
    ----------
    name : str, default is Undefined, required
        name
    namespace : str, default is Undefined, optional
        namespace
    """


    name: str

    namespace?: str


    check:
        len(name) >= 1
        len(namespace) >= 1


schema AivenIoV1alpha1KafkaSpecServiceIntegrationsItems0:
    """
    Service integrations to specify when creating a service. Not applied after initial service creation

    Attributes
    ----------
    integrationType : str, default is Undefined, required
        integration type
    sourceServiceName : str, default is Undefined, required
        source service name
    """


    integrationType: "read_replica"

    sourceServiceName: str


    check:
        len(sourceServiceName) <= 64
        len(sourceServiceName) >= 1


schema AivenIoV1alpha1KafkaSpecUserConfig:
    """
    Kafka specific user configuration options

    Attributes
    ----------
    additional_backup_regions : [str], default is Undefined, optional
        Additional Cloud Regions for Backup Replication
    custom_domain : str, default is Undefined, optional
        Serve the web frontend using a custom CNAME pointing to the Aiven DNS name
    ip_filter : [AivenIoV1alpha1KafkaSpecUserConfigIPFilterItems0], default is Undefined, optional
        Allow incoming connections from CIDR address block, e.g. '10.20.0.0/16'
    kafka : AivenIoV1alpha1KafkaSpecUserConfigKafka, default is Undefined, optional
        kafka
    kafka_authentication_methods : AivenIoV1alpha1KafkaSpecUserConfigKafkaAuthenticationMethods, default is Undefined, optional
        kafka authentication methods
    kafka_connect : bool, default is Undefined, optional
        Enable Kafka Connect service
    kafka_connect_config : AivenIoV1alpha1KafkaSpecUserConfigKafkaConnectConfig, default is Undefined, optional
        kafka connect config
    kafka_rest : bool, default is Undefined, optional
        Enable Kafka-REST service
    kafka_rest_authorization : bool, default is Undefined, optional
        Enable authorization in Kafka-REST service
    kafka_rest_config : AivenIoV1alpha1KafkaSpecUserConfigKafkaRestConfig, default is Undefined, optional
        kafka rest config
    kafka_version : str, default is Undefined, optional
        Kafka major version
    private_access : AivenIoV1alpha1KafkaSpecUserConfigPrivateAccess, default is Undefined, optional
        private access
    privatelink_access : AivenIoV1alpha1KafkaSpecUserConfigPrivatelinkAccess, default is Undefined, optional
        privatelink access
    public_access : AivenIoV1alpha1KafkaSpecUserConfigPublicAccess, default is Undefined, optional
        public access
    schema_registry : bool, default is Undefined, optional
        Enable Schema-Registry service
    schema_registry_config : AivenIoV1alpha1KafkaSpecUserConfigSchemaRegistryConfig, default is Undefined, optional
        schema registry config
    static_ips : bool, default is Undefined, optional
        Use static public IP addresses
    """


    additional_backup_regions?: [str]

    custom_domain?: str

    ip_filter?: [AivenIoV1alpha1KafkaSpecUserConfigIPFilterItems0]

    kafka?: AivenIoV1alpha1KafkaSpecUserConfigKafka

    kafka_authentication_methods?: AivenIoV1alpha1KafkaSpecUserConfigKafkaAuthenticationMethods

    kafka_connect?: bool

    kafka_connect_config?: AivenIoV1alpha1KafkaSpecUserConfigKafkaConnectConfig

    kafka_rest?: bool

    kafka_rest_authorization?: bool

    kafka_rest_config?: AivenIoV1alpha1KafkaSpecUserConfigKafkaRestConfig

    kafka_version?: "3.3"

    private_access?: AivenIoV1alpha1KafkaSpecUserConfigPrivateAccess

    privatelink_access?: AivenIoV1alpha1KafkaSpecUserConfigPrivatelinkAccess

    public_access?: AivenIoV1alpha1KafkaSpecUserConfigPublicAccess

    schema_registry?: bool

    schema_registry_config?: AivenIoV1alpha1KafkaSpecUserConfigSchemaRegistryConfig

    static_ips?: bool


    check:
        len(additional_backup_regions) <= 1
        len(custom_domain) <= 255
        len(ip_filter) <= 1024


schema AivenIoV1alpha1KafkaSpecUserConfigIPFilterItems0:
    """
    CIDR address block, either as a string, or in a dict with an optional description field

    Attributes
    ----------
    description : str, default is Undefined, optional
        Description for IP filter list entry
    network : str, default is Undefined, required
        CIDR address block
    """


    description?: str

    network: str


    check:
        len(description) <= 1024
        len(network) <= 43


schema AivenIoV1alpha1KafkaSpecUserConfigKafka:
    """
    Kafka broker configuration values

    Attributes
    ----------
    auto_create_topics_enable : bool, default is Undefined, optional
        Enable auto creation of topics
    compression_type : str, default is Undefined, optional
        Specify the final compression type for a given topic. This configuration accepts the standard compression codecs ('gzip', 'snappy', 'lz4', 'zstd'). It additionally accepts 'uncompressed' which is equivalent to no compression; and 'producer' which means retain the original compression codec set by the producer.
    connections_max_idle_ms : int, default is Undefined, optional
        Idle connections timeout: the server socket processor threads close the connections that idle for longer than this.
    default_replication_factor : int, default is Undefined, optional
        Replication factor for autocreated topics
    group_initial_rebalance_delay_ms : int, default is Undefined, optional
        The amount of time, in milliseconds, the group coordinator will wait for more consumers to join a new group before performing the first rebalance. A longer delay means potentially fewer rebalances, but increases the time until processing begins. The default value for this is 3 seconds. During development and testing it might be desirable to set this to 0 in order to not delay test execution time.
    group_max_session_timeout_ms : int, default is Undefined, optional
        The maximum allowed session timeout for registered consumers. Longer timeouts give consumers more time to process messages in between heartbeats at the cost of a longer time to detect failures.
    group_min_session_timeout_ms : int, default is Undefined, optional
        The minimum allowed session timeout for registered consumers. Longer timeouts give consumers more time to process messages in between heartbeats at the cost of a longer time to detect failures.
    log_cleaner_delete_retention_ms : int, default is Undefined, optional
        How long are delete records retained?
    log_cleaner_max_compaction_lag_ms : int, default is Undefined, optional
        The maximum amount of time message will remain uncompacted. Only applicable for logs that are being compacted
    log_cleaner_min_cleanable_ratio : float, default is Undefined, optional
        Controls log compactor frequency. Larger value means more frequent compactions but also more space wasted for logs. Consider setting log.cleaner.max.compaction.lag.ms to enforce compactions sooner, instead of setting a very high value for this option.
    log_cleaner_min_compaction_lag_ms : int, default is Undefined, optional
        The minimum time a message will remain uncompacted in the log. Only applicable for logs that are being compacted.
    log_cleanup_policy : str, default is Undefined, optional
        The default cleanup policy for segments beyond the retention window
    log_flush_interval_messages : int, default is Undefined, optional
        The number of messages accumulated on a log partition before messages are flushed to disk
    log_flush_interval_ms : int, default is Undefined, optional
        The maximum time in ms that a message in any topic is kept in memory before flushed to disk. If not set, the value in log.flush.scheduler.interval.ms is used
    log_index_interval_bytes : int, default is Undefined, optional
        The interval with which Kafka adds an entry to the offset index
    log_index_size_max_bytes : int, default is Undefined, optional
        The maximum size in bytes of the offset index
    log_message_downconversion_enable : bool, default is Undefined, optional
        This configuration controls whether down-conversion of message formats is enabled to satisfy consume requests.
    log_message_timestamp_difference_max_ms : int, default is Undefined, optional
        The maximum difference allowed between the timestamp when a broker receives a message and the timestamp specified in the message
    log_message_timestamp_type : str, default is Undefined, optional
        Define whether the timestamp in the message is message create time or log append time.
    log_preallocate : bool, default is Undefined, optional
        Should pre allocate file when create new segment?
    log_retention_bytes : int, default is Undefined, optional
        The maximum size of the log before deleting messages
    log_retention_hours : int, default is Undefined, optional
        The number of hours to keep a log file before deleting it
    log_retention_ms : int, default is Undefined, optional
        The number of milliseconds to keep a log file before deleting it (in milliseconds), If not set, the value in log.retention.minutes is used. If set to -1, no time limit is applied.
    log_roll_jitter_ms : int, default is Undefined, optional
        The maximum jitter to subtract from logRollTimeMillis (in milliseconds). If not set, the value in log.roll.jitter.hours is used
    log_roll_ms : int, default is Undefined, optional
        The maximum time before a new log segment is rolled out (in milliseconds).
    log_segment_bytes : int, default is Undefined, optional
        The maximum size of a single log file
    log_segment_delete_delay_ms : int, default is Undefined, optional
        The amount of time to wait before deleting a file from the filesystem
    max_connections_per_ip : int, default is Undefined, optional
        The maximum number of connections allowed from each ip address (defaults to 2147483647).
    max_incremental_fetch_session_cache_slots : int, default is Undefined, optional
        The maximum number of incremental fetch sessions that the broker will maintain.
    message_max_bytes : int, default is Undefined, optional
        The maximum size of message that the server can receive.
    min_insync_replicas : int, default is Undefined, optional
        When a producer sets acks to 'all' (or '-1'), min.insync.replicas specifies the minimum number of replicas that must acknowledge a write for the write to be considered successful.
    num_partitions : int, default is Undefined, optional
        Number of partitions for autocreated topics
    offsets_retention_minutes : int, default is Undefined, optional
        Log retention window in minutes for offsets topic
    producer_purgatory_purge_interval_requests : int, default is Undefined, optional
        The purge interval (in number of requests) of the producer request purgatory(defaults to 1000).
    replica_fetch_max_bytes : int, default is Undefined, optional
        The number of bytes of messages to attempt to fetch for each partition (defaults to 1048576). This is not an absolute maximum, if the first record batch in the first non-empty partition of the fetch is larger than this value, the record batch will still be returned to ensure that progress can be made.
    replica_fetch_response_max_bytes : int, default is Undefined, optional
        Maximum bytes expected for the entire fetch response (defaults to 10485760). Records are fetched in batches, and if the first record batch in the first non-empty partition of the fetch is larger than this value, the record batch will still be returned to ensure that progress can be made. As such, this is not an absolute maximum.
    socket_request_max_bytes : int, default is Undefined, optional
        The maximum number of bytes in a socket request (defaults to 104857600).
    transaction_remove_expired_transaction_cleanup_interval_ms : int, default is Undefined, optional
        The interval at which to remove transactions that have expired due to transactional.id.expiration.ms passing (defaults to 3600000 (1 hour)).
    transaction_state_log_segment_bytes : int, default is Undefined, optional
        The transaction topic segment bytes should be kept relatively small in order to facilitate faster log compaction and cache loads (defaults to 104857600 (100 mebibytes)).
    """


    auto_create_topics_enable?: bool

    compression_type?: "gzip" | "snappy" | "lz4" | "zstd" | "uncompressed" | "producer"

    connections_max_idle_ms?: int

    default_replication_factor?: int

    group_initial_rebalance_delay_ms?: int

    group_max_session_timeout_ms?: int

    group_min_session_timeout_ms?: int

    log_cleaner_delete_retention_ms?: int

    log_cleaner_max_compaction_lag_ms?: int

    log_cleaner_min_cleanable_ratio?: float

    log_cleaner_min_compaction_lag_ms?: int

    log_cleanup_policy?: "delete" | "compact" | "compact,delete"

    log_flush_interval_messages?: int

    log_flush_interval_ms?: int

    log_index_interval_bytes?: int

    log_index_size_max_bytes?: int

    log_message_downconversion_enable?: bool

    log_message_timestamp_difference_max_ms?: int

    log_message_timestamp_type?: "CreateTime" | "LogAppendTime"

    log_preallocate?: bool

    log_retention_bytes?: int

    log_retention_hours?: int

    log_retention_ms?: int

    log_roll_jitter_ms?: int

    log_roll_ms?: int

    log_segment_bytes?: int

    log_segment_delete_delay_ms?: int

    max_connections_per_ip?: int

    max_incremental_fetch_session_cache_slots?: int

    message_max_bytes?: int

    min_insync_replicas?: int

    num_partitions?: int

    offsets_retention_minutes?: int

    producer_purgatory_purge_interval_requests?: int

    replica_fetch_max_bytes?: int

    replica_fetch_response_max_bytes?: int

    socket_request_max_bytes?: int

    transaction_remove_expired_transaction_cleanup_interval_ms?: int

    transaction_state_log_segment_bytes?: int


    check:
        connections_max_idle_ms <= 3.6e+06
        connections_max_idle_ms >= 1000
        default_replication_factor <= 10
        default_replication_factor >= 1
        group_initial_rebalance_delay_ms <= 300000
        group_initial_rebalance_delay_ms >= 0
        group_max_session_timeout_ms <= 1.8e+06
        group_max_session_timeout_ms >= 0
        group_min_session_timeout_ms <= 60000
        group_min_session_timeout_ms >= 0
        log_cleaner_delete_retention_ms <= 3.1556926e+11
        log_cleaner_delete_retention_ms >= 0
        log_cleaner_max_compaction_lag_ms >= 30000
        log_cleaner_min_cleanable_ratio <= 0.9
        log_cleaner_min_cleanable_ratio >= 0.2
        log_cleaner_min_compaction_lag_ms >= 0
        log_flush_interval_messages >= 1
        log_flush_interval_ms >= 0
        log_index_interval_bytes <= 1.048576e+08
        log_index_interval_bytes >= 0
        log_index_size_max_bytes <= 1.048576e+08
        log_index_size_max_bytes >= 1.048576e+06
        log_message_timestamp_difference_max_ms >= 0
        log_retention_bytes >= -1
        log_retention_hours <= 2.147483647e+09
        log_retention_hours >= -1
        log_retention_ms >= -1
        log_roll_jitter_ms >= 0
        log_roll_ms >= 1
        log_segment_bytes <= 1.073741824e+09
        log_segment_bytes >= 1.048576e+07
        log_segment_delete_delay_ms <= 3.6e+06
        log_segment_delete_delay_ms >= 0
        max_connections_per_ip <= 2.147483647e+09
        max_connections_per_ip >= 256
        max_incremental_fetch_session_cache_slots <= 10000
        max_incremental_fetch_session_cache_slots >= 1000
        message_max_bytes <= 1.000012e+08
        message_max_bytes >= 0
        min_insync_replicas <= 7
        min_insync_replicas >= 1
        num_partitions <= 1000
        num_partitions >= 1
        offsets_retention_minutes <= 2.147483647e+09
        offsets_retention_minutes >= 1
        producer_purgatory_purge_interval_requests <= 10000
        producer_purgatory_purge_interval_requests >= 10
        replica_fetch_max_bytes <= 1.048576e+08
        replica_fetch_max_bytes >= 1.048576e+06
        replica_fetch_response_max_bytes <= 1.048576e+09
        replica_fetch_response_max_bytes >= 1.048576e+07
        socket_request_max_bytes <= 2.097152e+08
        socket_request_max_bytes >= 1.048576e+07
        transaction_remove_expired_transaction_cleanup_interval_ms <= 3.6e+06
        transaction_remove_expired_transaction_cleanup_interval_ms >= 600000
        transaction_state_log_segment_bytes <= 2.147483647e+09
        transaction_state_log_segment_bytes >= 1.048576e+06


schema AivenIoV1alpha1KafkaSpecUserConfigKafkaAuthenticationMethods:
    """
    Kafka authentication methods

    Attributes
    ----------
    certificate : bool, default is Undefined, optional
        Enable certificate/SSL authentication
    sasl : bool, default is Undefined, optional
        Enable SASL authentication
    """


    certificate?: bool

    sasl?: bool


schema AivenIoV1alpha1KafkaSpecUserConfigKafkaConnectConfig:
    """
    Kafka Connect configuration values

    Attributes
    ----------
    connector_client_config_override_policy : str, default is Undefined, optional
        Defines what client configurations can be overridden by the connector. Default is None
    consumer_auto_offset_reset : str, default is Undefined, optional
        What to do when there is no initial offset in Kafka or if the current offset does not exist any more on the server. Default is earliest
    consumer_fetch_max_bytes : int, default is Undefined, optional
        Records are fetched in batches by the consumer, and if the first record batch in the first non-empty partition of the fetch is larger than this value, the record batch will still be returned to ensure that the consumer can make progress. As such, this is not a absolute maximum.
    consumer_isolation_level : str, default is Undefined, optional
        Transaction read isolation level. read_uncommitted is the default, but read_committed can be used if consume-exactly-once behavior is desired.
    consumer_max_partition_fetch_bytes : int, default is Undefined, optional
        Records are fetched in batches by the consumer.If the first record batch in the first non-empty partition of the fetch is larger than this limit, the batch will still be returned to ensure that the consumer can make progress.
    consumer_max_poll_interval_ms : int, default is Undefined, optional
        The maximum delay in milliseconds between invocations of poll() when using consumer group management (defaults to 300000).
    consumer_max_poll_records : int, default is Undefined, optional
        The maximum number of records returned in a single call to poll() (defaults to 500).
    offset_flush_interval_ms : int, default is Undefined, optional
        The interval at which to try committing offsets for tasks (defaults to 60000).
    offset_flush_timeout_ms : int, default is Undefined, optional
        Maximum number of milliseconds to wait for records to flush and partition offset data to be committed to offset storage before cancelling the process and restoring the offset data to be committed in a future attempt (defaults to 5000).
    producer_batch_size : int, default is Undefined, optional
        This setting gives the upper bound of the batch size to be sent. If there are fewer than this many bytes accumulated for this partition, the producer will 'linger' for the linger.ms time waiting for more records to show up. A batch size of zero will disable batching entirely (defaults to 16384).
    producer_buffer_memory : int, default is Undefined, optional
        The total bytes of memory the producer can use to buffer records waiting to be sent to the broker (defaults to 33554432).
    producer_compression_type : str, default is Undefined, optional
        Specify the default compression type for producers. This configuration accepts the standard compression codecs ('gzip', 'snappy', 'lz4', 'zstd'). It additionally accepts 'none' which is the default and equivalent to no compression.
    producer_linger_ms : int, default is Undefined, optional
        This setting gives the upper bound on the delay for batching: once there is batch.size worth of records for a partition it will be sent immediately regardless of this setting, however if there are fewer than this many bytes accumulated for this partition the producer will 'linger' for the specified time waiting for more records to show up. Defaults to 0.
    producer_max_request_size : int, default is Undefined, optional
        This setting will limit the number of record batches the producer will send in a single request to avoid sending huge requests.
    session_timeout_ms : int, default is Undefined, optional
        The timeout in milliseconds used to detect failures when using Kafkaâ€™s group management facilities (defaults to 10000).
    """


    connector_client_config_override_policy?: "None" | "All"

    consumer_auto_offset_reset?: "earliest" | "latest"

    consumer_fetch_max_bytes?: int

    consumer_isolation_level?: "read_uncommitted" | "read_committed"

    consumer_max_partition_fetch_bytes?: int

    consumer_max_poll_interval_ms?: int

    consumer_max_poll_records?: int

    offset_flush_interval_ms?: int

    offset_flush_timeout_ms?: int

    producer_batch_size?: int

    producer_buffer_memory?: int

    producer_compression_type?: "gzip" | "snappy" | "lz4" | "zstd" | "none"

    producer_linger_ms?: int

    producer_max_request_size?: int

    session_timeout_ms?: int


    check:
        consumer_fetch_max_bytes <= 1.048576e+08
        consumer_fetch_max_bytes >= 1.048576e+06
        consumer_max_partition_fetch_bytes <= 1.048576e+08
        consumer_max_partition_fetch_bytes >= 1.048576e+06
        consumer_max_poll_interval_ms <= 2.147483647e+09
        consumer_max_poll_interval_ms >= 1
        consumer_max_poll_records <= 10000
        consumer_max_poll_records >= 1
        offset_flush_interval_ms <= 1e+08
        offset_flush_interval_ms >= 1
        offset_flush_timeout_ms <= 2.147483647e+09
        offset_flush_timeout_ms >= 1
        producer_batch_size <= 5.24288e+06
        producer_batch_size >= 0
        producer_buffer_memory <= 1.34217728e+08
        producer_buffer_memory >= 5.24288e+06
        producer_linger_ms <= 5000
        producer_linger_ms >= 0
        producer_max_request_size <= 6.7108864e+07
        producer_max_request_size >= 131072
        session_timeout_ms <= 2.147483647e+09
        session_timeout_ms >= 1


schema AivenIoV1alpha1KafkaSpecUserConfigKafkaRestConfig:
    """
    Kafka REST configuration

    Attributes
    ----------
    consumer_enable_auto_commit : bool, default is Undefined, optional
        If true the consumer's offset will be periodically committed to Kafka in the background
    consumer_request_max_bytes : int, default is Undefined, optional
        Maximum number of bytes in unencoded message keys and values by a single request
    consumer_request_timeout_ms : int, default is Undefined, optional
        The maximum total time to wait for messages for a request if the maximum number of messages has not yet been reached
    producer_acks : str, default is Undefined, optional
        The number of acknowledgments the producer requires the leader to have received before considering a request complete. If set to 'all' or '-1', the leader will wait for the full set of in-sync replicas to acknowledge the record.
    producer_compression_type : str, default is Undefined, optional
        Specify the default compression type for producers. This configuration accepts the standard compression codecs ('gzip', 'snappy', 'lz4', 'zstd'). It additionally accepts 'none' which is the default and equivalent to no compression.
    producer_linger_ms : int, default is Undefined, optional
        Wait for up to the given delay to allow batching records together
    simpleconsumer_pool_size_max : int, default is Undefined, optional
        Maximum number of SimpleConsumers that can be instantiated per broker
    """


    consumer_enable_auto_commit?: bool

    consumer_request_max_bytes?: int

    consumer_request_timeout_ms?: 1000 | 15000 | 30000

    producer_acks?: "all" | "-1" | "0" | "1"

    producer_compression_type?: "gzip" | "snappy" | "lz4" | "zstd" | "none"

    producer_linger_ms?: int

    simpleconsumer_pool_size_max?: int


    check:
        consumer_request_max_bytes <= 6.7108864e+08
        consumer_request_max_bytes >= 0
        consumer_request_timeout_ms <= 30000
        consumer_request_timeout_ms >= 1000
        producer_linger_ms <= 5000
        producer_linger_ms >= 0
        simpleconsumer_pool_size_max <= 250
        simpleconsumer_pool_size_max >= 10


schema AivenIoV1alpha1KafkaSpecUserConfigPrivateAccess:
    """
    Allow access to selected service ports from private networks

    Attributes
    ----------
    kafka : bool, default is Undefined, optional
        Allow clients to connect to kafka with a DNS name that always resolves to the service's private IP addresses. Only available in certain network locations
    kafka_connect : bool, default is Undefined, optional
        Allow clients to connect to kafka_connect with a DNS name that always resolves to the service's private IP addresses. Only available in certain network locations
    kafka_rest : bool, default is Undefined, optional
        Allow clients to connect to kafka_rest with a DNS name that always resolves to the service's private IP addresses. Only available in certain network locations
    prometheus : bool, default is Undefined, optional
        Allow clients to connect to prometheus with a DNS name that always resolves to the service's private IP addresses. Only available in certain network locations
    schema_registry : bool, default is Undefined, optional
        Allow clients to connect to schema_registry with a DNS name that always resolves to the service's private IP addresses. Only available in certain network locations
    """


    kafka?: bool

    kafka_connect?: bool

    kafka_rest?: bool

    prometheus?: bool

    schema_registry?: bool


schema AivenIoV1alpha1KafkaSpecUserConfigPrivatelinkAccess:
    """
    Allow access to selected service components through Privatelink

    Attributes
    ----------
    jolokia : bool, default is Undefined, optional
        Enable jolokia
    kafka : bool, default is Undefined, optional
        Enable kafka
    kafka_connect : bool, default is Undefined, optional
        Enable kafka_connect
    kafka_rest : bool, default is Undefined, optional
        Enable kafka_rest
    prometheus : bool, default is Undefined, optional
        Enable prometheus
    schema_registry : bool, default is Undefined, optional
        Enable schema_registry
    """


    jolokia?: bool

    kafka?: bool

    kafka_connect?: bool

    kafka_rest?: bool

    prometheus?: bool

    schema_registry?: bool


schema AivenIoV1alpha1KafkaSpecUserConfigPublicAccess:
    """
    Allow access to selected service ports from the public Internet

    Attributes
    ----------
    kafka : bool, default is Undefined, optional
        Allow clients to connect to kafka from the public internet for service nodes that are in a project VPC or another type of private network
    kafka_connect : bool, default is Undefined, optional
        Allow clients to connect to kafka_connect from the public internet for service nodes that are in a project VPC or another type of private network
    kafka_rest : bool, default is Undefined, optional
        Allow clients to connect to kafka_rest from the public internet for service nodes that are in a project VPC or another type of private network
    prometheus : bool, default is Undefined, optional
        Allow clients to connect to prometheus from the public internet for service nodes that are in a project VPC or another type of private network
    schema_registry : bool, default is Undefined, optional
        Allow clients to connect to schema_registry from the public internet for service nodes that are in a project VPC or another type of private network
    """


    kafka?: bool

    kafka_connect?: bool

    kafka_rest?: bool

    prometheus?: bool

    schema_registry?: bool


schema AivenIoV1alpha1KafkaSpecUserConfigSchemaRegistryConfig:
    """
    Schema Registry configuration

    Attributes
    ----------
    leader_eligibility : bool, default is Undefined, optional
        If true, Karapace / Schema Registry on the service nodes can participate in leader election. It might be needed to disable this when the schemas topic is replicated to a secondary cluster and Karapace / Schema Registry there must not participate in leader election. Defaults to `true`.
    topic_name : str, default is Undefined, optional
        The durable single partition topic that acts as the durable log for the data. This topic must be compacted to avoid losing data due to retention policy. Please note that changing this configuration in an existing Schema Registry / Karapace setup leads to previous schemas being inaccessible, data encoded with them potentially unreadable and schema ID sequence put out of order. It's only possible to do the switch while Schema Registry / Karapace is disabled. Defaults to `_schemas`.
    """


    leader_eligibility?: bool

    topic_name?: str


    check:
        len(topic_name) <= 249
        len(topic_name) >= 1


schema AivenIoV1alpha1KafkaStatus:
    """
    ServiceStatus defines the observed state of service

    Attributes
    ----------
    conditions : [AivenIoV1alpha1KafkaStatusConditionsItems0], default is Undefined, required
        Conditions represent the latest available observations of a service state
    state : str, default is Undefined, required
        Service state
    """


    conditions: [AivenIoV1alpha1KafkaStatusConditionsItems0]

    state: str


schema AivenIoV1alpha1KafkaStatusConditionsItems0:
    """
    Condition contains details for one aspect of the current state of this API Resource. --- This struct is intended for direct use as an array at the field path .status.conditions.  For example, 
     type FooStatus struct{ // Represents the observations of a foo's current state. // Known .status.conditions.type are: "Available", "Progressing", and "Degraded" // +patchMergeKey=type // +patchStrategy=merge // +listType=map // +listMapKey=type Conditions []metav1.Condition `json:"conditions,omitempty" patchStrategy:"merge" patchMergeKey:"type" protobuf:"bytes,1,rep,name=conditions"` 
     // other fields }

    Attributes
    ----------
    lastTransitionTime : str, default is Undefined, required
        lastTransitionTime is the last time the condition transitioned from one status to another. This should be when the underlying condition changed.  If that is not known, then using the time when the API field changed is acceptable.
    message : str, default is Undefined, required
        message is a human readable message indicating details about the transition. This may be an empty string.
    observedGeneration : int, default is Undefined, optional
        observedGeneration represents the .metadata.generation that the condition was set based upon. For instance, if .metadata.generation is currently 12, but the .status.conditions[x].observedGeneration is 9, the condition is out of date with respect to the current state of the instance.
    reason : str, default is Undefined, required
        reason contains a programmatic identifier indicating the reason for the condition's last transition. Producers of specific condition types may define expected values and meanings for this field, and whether the values are considered a guaranteed API. The value should be a CamelCase string. This field may not be empty.
    status : str, default is Undefined, required
        status of the condition, one of True, False, Unknown.
    $type : str, default is Undefined, required
        type of condition in CamelCase or in foo.example.com/CamelCase. --- Many .condition.type values are consistent across resources like Available, but because arbitrary conditions can be useful (see .node.status.conditions), the ability to deconflict is important. The regex it matches is (dns1123SubdomainFmt/)?(qualifiedNameFmt)
    """


    lastTransitionTime: str

    message: str

    observedGeneration?: int

    reason: str

    status: "True" | "False" | "Unknown"

    $type: str


    check:
        len(message) <= 32768
        observedGeneration >= 0
        len(reason) <= 1024
        len(reason) >= 1
        regex.match(str(reason), r"^[A-Za-z]([A-Za-z0-9_,:]*[A-Za-z0-9_])?$")
        len($type) <= 316
        regex.match(str($type), r"^([a-z0-9]([-a-z0-9]*[a-z0-9])?(\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*/)?(([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9])$")


