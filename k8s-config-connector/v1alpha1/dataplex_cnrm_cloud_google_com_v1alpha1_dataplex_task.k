"""
This file was generated by the KCL auto-gen tool. DO NOT EDIT.
Editing this file might prove futile when you re-run the KCL auto-gen generate command.
"""
import k8s.apimachinery.pkg.apis.meta.v1


schema DataplexTask:
    r"""
    DataplexTask is the Schema for the DataplexTask API

    Attributes
    ----------
    apiVersion : str, default is "dataplex.cnrm.cloud.google.com/v1alpha1", required
        APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources
    kind : str, default is "DataplexTask", required
        Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
    metadata : v1.ObjectMeta, default is Undefined, optional
        metadata
    spec : DataplexCnrmCloudGoogleComV1alpha1DataplexTaskSpec, default is Undefined, required
        spec
    status : DataplexCnrmCloudGoogleComV1alpha1DataplexTaskStatus, default is Undefined, optional
        status
    """


    apiVersion: "dataplex.cnrm.cloud.google.com/v1alpha1" = "dataplex.cnrm.cloud.google.com/v1alpha1"

    kind: "DataplexTask" = "DataplexTask"

    metadata?: v1.ObjectMeta

    spec: DataplexCnrmCloudGoogleComV1alpha1DataplexTaskSpec

    status?: DataplexCnrmCloudGoogleComV1alpha1DataplexTaskStatus


schema DataplexCnrmCloudGoogleComV1alpha1DataplexTaskSpec:
    r"""
    DataplexTaskSpec defines the desired state of DataplexTask

    Attributes
    ----------
    description : str, default is Undefined, optional
        Optional. Description of the task.
    displayName : str, default is Undefined, optional
        Optional. User friendly display name.
    executionSpec : DataplexCnrmCloudGoogleComV1alpha1DataplexTaskSpecExecutionSpec, default is Undefined, required
        execution spec
    lakeRef : DataplexCnrmCloudGoogleComV1alpha1DataplexTaskSpecLakeRef, default is Undefined, optional
        lake ref
    notebook : DataplexCnrmCloudGoogleComV1alpha1DataplexTaskSpecNotebook, default is Undefined, optional
        notebook
    resourceID : str, default is Undefined, optional
        The DataplexTask name. If not given, the metadata.name will be used.
    spark : DataplexCnrmCloudGoogleComV1alpha1DataplexTaskSpecSpark, default is Undefined, optional
        spark
    triggerSpec : DataplexCnrmCloudGoogleComV1alpha1DataplexTaskSpecTriggerSpec, default is Undefined, optional
        trigger spec
    """


    description?: str

    displayName?: str

    executionSpec: DataplexCnrmCloudGoogleComV1alpha1DataplexTaskSpecExecutionSpec

    lakeRef?: DataplexCnrmCloudGoogleComV1alpha1DataplexTaskSpecLakeRef

    notebook?: DataplexCnrmCloudGoogleComV1alpha1DataplexTaskSpecNotebook

    resourceID?: str

    spark?: DataplexCnrmCloudGoogleComV1alpha1DataplexTaskSpecSpark

    triggerSpec?: DataplexCnrmCloudGoogleComV1alpha1DataplexTaskSpecTriggerSpec


schema DataplexCnrmCloudGoogleComV1alpha1DataplexTaskSpecExecutionSpec:
    r"""
    Required. Spec related to how a task is executed.

    Attributes
    ----------
    args : {str:str}, default is Undefined, optional
        Optional. The arguments to pass to the task. The args can use placeholders of the format ${placeholder} as part of key/value string. These will be interpolated before passing the args to the driver. Currently supported placeholders: - ${task_id} - ${job_time} To pass positional args, set the key as TASK_ARGS. The value should be a comma-separated string of all the positional arguments. To use a delimiter other than comma, refer to https://cloud.google.com/sdk/gcloud/reference/topic/escaping. In case of other keys being present in the args, then TASK_ARGS will be passed as the last argument.
    kmsKeyRef : DataplexCnrmCloudGoogleComV1alpha1DataplexTaskSpecExecutionSpecKmsKeyRef, default is Undefined, optional
        kms key ref
    maxJobExecutionLifetime : str, default is Undefined, optional
        Optional. The maximum duration after which the job execution is expired.
    projectRef : DataplexCnrmCloudGoogleComV1alpha1DataplexTaskSpecExecutionSpecProjectRef, default is Undefined, optional
        project ref
    serviceAccountRef : DataplexCnrmCloudGoogleComV1alpha1DataplexTaskSpecExecutionSpecServiceAccountRef, default is Undefined, required
        service account ref
    """


    args?: {str:str}

    kmsKeyRef?: DataplexCnrmCloudGoogleComV1alpha1DataplexTaskSpecExecutionSpecKmsKeyRef

    maxJobExecutionLifetime?: str

    projectRef?: DataplexCnrmCloudGoogleComV1alpha1DataplexTaskSpecExecutionSpecProjectRef

    serviceAccountRef: DataplexCnrmCloudGoogleComV1alpha1DataplexTaskSpecExecutionSpecServiceAccountRef


schema DataplexCnrmCloudGoogleComV1alpha1DataplexTaskSpecExecutionSpecKmsKeyRef:
    r"""
    Optional. The Cloud KMS key to use for encryption, of the form: `projects/{project_number}/locations/{location_id}/keyRings/{key-ring-name}/cryptoKeys/{key-name}`.

    Attributes
    ----------
    external : str, default is Undefined, optional
        A reference to an externally managed KMSCryptoKey. Should be in the format `projects/[kms_project_id]/locations/[region]/keyRings/[key_ring_id]/cryptoKeys/[key]`.
    name : str, default is Undefined, optional
        The `name` of a `KMSCryptoKey` resource.
    namespace : str, default is Undefined, optional
        The `namespace` of a `KMSCryptoKey` resource.
    """


    external?: str

    name?: str

    namespace?: str


schema DataplexCnrmCloudGoogleComV1alpha1DataplexTaskSpecExecutionSpecProjectRef:
    r"""
    Optional. The project in which jobs are run. By default, the project containing the Lake is used. If a project is provided, the [ExecutionSpec.service_account][google.cloud.dataplex.v1.Task.ExecutionSpec.service_account] must belong to this project.

    Attributes
    ----------
    external : str, default is Undefined, optional
        The `projectID` field of a project, when not managed by Config Connector.
    kind : str, default is Undefined, optional
        The kind of the Project resource; optional but must be `Project` if provided.
    name : str, default is Undefined, optional
        The `name` field of a `Project` resource.
    namespace : str, default is Undefined, optional
        The `namespace` field of a `Project` resource.
    """


    external?: str

    kind?: str

    name?: str

    namespace?: str


schema DataplexCnrmCloudGoogleComV1alpha1DataplexTaskSpecExecutionSpecServiceAccountRef:
    r"""
    Required. Service account to use to execute a task. If not provided, the default Compute service account for the project is used.

    Attributes
    ----------
    external : str, default is Undefined, optional
        The `email` field of an `IAMServiceAccount` resource.
    name : str, default is Undefined, optional
        Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
    namespace : str, default is Undefined, optional
        Namespace of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/
    """


    external?: str

    name?: str

    namespace?: str


schema DataplexCnrmCloudGoogleComV1alpha1DataplexTaskSpecLakeRef:
    r"""
    LakeRef defines the resource reference to DataplexLake, which "External" field holds the GCP identifier for the KRM object.

    Attributes
    ----------
    external : str, default is Undefined, optional
        A reference to an externally managed DataplexLake resource. Should be in the format "projects/{{projectID}}/locations/{{location}}/lakes/{{lakeID}}".
    name : str, default is Undefined, optional
        The name of a DataplexLake resource.
    namespace : str, default is Undefined, optional
        The namespace of a DataplexLake resource.
    """


    external?: str

    name?: str

    namespace?: str


schema DataplexCnrmCloudGoogleComV1alpha1DataplexTaskSpecNotebook:
    r"""
    Config related to running scheduled Notebooks. Exactly one of spark or notebook must be set.

    Attributes
    ----------
    archiveURIs : [str], default is Undefined, optional
        Optional. Cloud Storage URIs of archives to be extracted into the working directory of each executor. Supported file types: .jar, .tar, .tar.gz, .tgz, and .zip.
    fileURIs : [str], default is Undefined, optional
        Optional. Cloud Storage URIs of files to be placed in the working directory of each executor.
    infrastructureSpec : DataplexCnrmCloudGoogleComV1alpha1DataplexTaskSpecNotebookInfrastructureSpec, default is Undefined, optional
        infrastructure spec
    notebook : str, default is Undefined, required
        Required. Path to input notebook. This can be the Cloud Storage URI of the notebook file or the path to a Notebook Content. The execution args are accessible as environment variables (`TASK_key=value`).
    """


    archiveURIs?: [str]

    fileURIs?: [str]

    infrastructureSpec?: DataplexCnrmCloudGoogleComV1alpha1DataplexTaskSpecNotebookInfrastructureSpec

    notebook: str


schema DataplexCnrmCloudGoogleComV1alpha1DataplexTaskSpecNotebookInfrastructureSpec:
    r"""
    Optional. Infrastructure specification for the execution.

    Attributes
    ----------
    batch : DataplexCnrmCloudGoogleComV1alpha1DataplexTaskSpecNotebookInfrastructureSpecBatch, default is Undefined, optional
        batch
    containerImage : DataplexCnrmCloudGoogleComV1alpha1DataplexTaskSpecNotebookInfrastructureSpecContainerImage, default is Undefined, optional
        container image
    vpcNetwork : DataplexCnrmCloudGoogleComV1alpha1DataplexTaskSpecNotebookInfrastructureSpecVpcNetwork, default is Undefined, optional
        vpc network
    """


    batch?: DataplexCnrmCloudGoogleComV1alpha1DataplexTaskSpecNotebookInfrastructureSpecBatch

    containerImage?: DataplexCnrmCloudGoogleComV1alpha1DataplexTaskSpecNotebookInfrastructureSpecContainerImage

    vpcNetwork?: DataplexCnrmCloudGoogleComV1alpha1DataplexTaskSpecNotebookInfrastructureSpecVpcNetwork


schema DataplexCnrmCloudGoogleComV1alpha1DataplexTaskSpecNotebookInfrastructureSpecBatch:
    r"""
    Compute resources needed for a Task when using Dataproc Serverless.

    Attributes
    ----------
    executorsCount : int, default is Undefined, optional
        Optional. Total number of job executors. Executor Count should be between 2 and 100. [Default=2]
    maxExecutorsCount : int, default is Undefined, optional
        Optional. Max configurable executors. If max_executors_count > executors_count, then auto-scaling is enabled. Max Executor Count should be between 2 and 1000. [Default=1000]
    """


    executorsCount?: int

    maxExecutorsCount?: int


schema DataplexCnrmCloudGoogleComV1alpha1DataplexTaskSpecNotebookInfrastructureSpecContainerImage:
    r"""
    Container Image Runtime Configuration.

    Attributes
    ----------
    image : str, default is Undefined, optional
        Optional. Container image to use.
    javaJars : [str], default is Undefined, optional
        Optional. A list of Java JARS to add to the classpath. Valid input includes Cloud Storage URIs to Jar binaries. For example, gs://bucket-name/my/path/to/file.jar
    properties : {str:str}, default is Undefined, optional
        Optional. Override to common configuration of open source components installed on the Dataproc cluster. The properties to set on daemon config files. Property keys are specified in `prefix:property` format, for example `core:hadoop.tmp.dir`. For more information, see [Cluster properties](https://cloud.google.com/dataproc/docs/concepts/cluster-properties).
    pythonPackages : [str], default is Undefined, optional
        Optional. A list of python packages to be installed. Valid formats include Cloud Storage URI to a PIP installable library. For example, gs://bucket-name/my/path/to/lib.tar.gz
    """


    image?: str

    javaJars?: [str]

    properties?: {str:str}

    pythonPackages?: [str]


schema DataplexCnrmCloudGoogleComV1alpha1DataplexTaskSpecNotebookInfrastructureSpecVpcNetwork:
    r"""
    Vpc network.

    Attributes
    ----------
    network : str, default is Undefined, optional
        Optional. The Cloud VPC network in which the job is run. By default, the Cloud VPC network named Default within the project is used.
    networkTags : [str], default is Undefined, optional
        Optional. List of network tags to apply to the job.
    subNetwork : str, default is Undefined, optional
        Optional. The Cloud VPC sub-network in which the job is run.
    """


    network?: str

    networkTags?: [str]

    subNetwork?: str


schema DataplexCnrmCloudGoogleComV1alpha1DataplexTaskSpecSpark:
    r"""
    Config related to running custom Spark tasks. Exactly one of spark or notebook must be set.

    Attributes
    ----------
    archiveURIs : [str], default is Undefined, optional
        Optional. Cloud Storage URIs of archives to be extracted into the working directory of each executor. Supported file types: .jar, .tar, .tar.gz, .tgz, and .zip.
    fileURIs : [str], default is Undefined, optional
        Optional. Cloud Storage URIs of files to be placed in the working directory of each executor.
    infrastructureSpec : DataplexCnrmCloudGoogleComV1alpha1DataplexTaskSpecSparkInfrastructureSpec, default is Undefined, optional
        infrastructure spec
    mainClass : str, default is Undefined, optional
        The name of the driver's main class. The jar file that contains the class must be in the default CLASSPATH or specified in `jar_file_uris`. The execution args are passed in as a sequence of named process arguments (`--key=value`).
    mainJarFileURI : str, default is Undefined, optional
        The Cloud Storage URI of the jar file that contains the main class. The execution args are passed in as a sequence of named process arguments (`--key=value`).
    pythonScriptFile : str, default is Undefined, optional
        The Gcloud Storage URI of the main Python file to use as the driver. Must be a .py file. The execution args are passed in as a sequence of named process arguments (`--key=value`).
    sqlScript : str, default is Undefined, optional
        The query text. The execution args are used to declare a set of script variables (`set key="value";`).
    sqlScriptFile : str, default is Undefined, optional
        A reference to a query file. This should be the Cloud Storage URI of the query file. The execution args are used to declare a set of script variables (`set key="value";`).
    """


    archiveURIs?: [str]

    fileURIs?: [str]

    infrastructureSpec?: DataplexCnrmCloudGoogleComV1alpha1DataplexTaskSpecSparkInfrastructureSpec

    mainClass?: str

    mainJarFileURI?: str

    pythonScriptFile?: str

    sqlScript?: str

    sqlScriptFile?: str


schema DataplexCnrmCloudGoogleComV1alpha1DataplexTaskSpecSparkInfrastructureSpec:
    r"""
    Optional. Infrastructure specification for the execution.

    Attributes
    ----------
    batch : DataplexCnrmCloudGoogleComV1alpha1DataplexTaskSpecSparkInfrastructureSpecBatch, default is Undefined, optional
        batch
    containerImage : DataplexCnrmCloudGoogleComV1alpha1DataplexTaskSpecSparkInfrastructureSpecContainerImage, default is Undefined, optional
        container image
    vpcNetwork : DataplexCnrmCloudGoogleComV1alpha1DataplexTaskSpecSparkInfrastructureSpecVpcNetwork, default is Undefined, optional
        vpc network
    """


    batch?: DataplexCnrmCloudGoogleComV1alpha1DataplexTaskSpecSparkInfrastructureSpecBatch

    containerImage?: DataplexCnrmCloudGoogleComV1alpha1DataplexTaskSpecSparkInfrastructureSpecContainerImage

    vpcNetwork?: DataplexCnrmCloudGoogleComV1alpha1DataplexTaskSpecSparkInfrastructureSpecVpcNetwork


schema DataplexCnrmCloudGoogleComV1alpha1DataplexTaskSpecSparkInfrastructureSpecBatch:
    r"""
    Compute resources needed for a Task when using Dataproc Serverless.

    Attributes
    ----------
    executorsCount : int, default is Undefined, optional
        Optional. Total number of job executors. Executor Count should be between 2 and 100. [Default=2]
    maxExecutorsCount : int, default is Undefined, optional
        Optional. Max configurable executors. If max_executors_count > executors_count, then auto-scaling is enabled. Max Executor Count should be between 2 and 1000. [Default=1000]
    """


    executorsCount?: int

    maxExecutorsCount?: int


schema DataplexCnrmCloudGoogleComV1alpha1DataplexTaskSpecSparkInfrastructureSpecContainerImage:
    r"""
    Container Image Runtime Configuration.

    Attributes
    ----------
    image : str, default is Undefined, optional
        Optional. Container image to use.
    javaJars : [str], default is Undefined, optional
        Optional. A list of Java JARS to add to the classpath. Valid input includes Cloud Storage URIs to Jar binaries. For example, gs://bucket-name/my/path/to/file.jar
    properties : {str:str}, default is Undefined, optional
        Optional. Override to common configuration of open source components installed on the Dataproc cluster. The properties to set on daemon config files. Property keys are specified in `prefix:property` format, for example `core:hadoop.tmp.dir`. For more information, see [Cluster properties](https://cloud.google.com/dataproc/docs/concepts/cluster-properties).
    pythonPackages : [str], default is Undefined, optional
        Optional. A list of python packages to be installed. Valid formats include Cloud Storage URI to a PIP installable library. For example, gs://bucket-name/my/path/to/lib.tar.gz
    """


    image?: str

    javaJars?: [str]

    properties?: {str:str}

    pythonPackages?: [str]


schema DataplexCnrmCloudGoogleComV1alpha1DataplexTaskSpecSparkInfrastructureSpecVpcNetwork:
    r"""
    Vpc network.

    Attributes
    ----------
    network : str, default is Undefined, optional
        Optional. The Cloud VPC network in which the job is run. By default, the Cloud VPC network named Default within the project is used.
    networkTags : [str], default is Undefined, optional
        Optional. List of network tags to apply to the job.
    subNetwork : str, default is Undefined, optional
        Optional. The Cloud VPC sub-network in which the job is run.
    """


    network?: str

    networkTags?: [str]

    subNetwork?: str


schema DataplexCnrmCloudGoogleComV1alpha1DataplexTaskSpecTriggerSpec:
    r"""
    Required. Spec related to how often and when a task should be triggered.

    Attributes
    ----------
    disabled : bool, default is Undefined, optional
        Optional. Prevent the task from executing. This does not cancel already running tasks. It is intended to temporarily disable RECURRING tasks.
    maxRetries : int, default is Undefined, optional
        Optional. Number of retry attempts before aborting. Set to zero to never attempt to retry a failed task.
    schedule : str, default is Undefined, optional
        Optional. Cron schedule (https://en.wikipedia.org/wiki/Cron) for running tasks periodically. To explicitly set a timezone to the cron tab, apply a prefix in the cron tab: "CRON_TZ=${IANA_TIME_ZONE}" or "TZ=${IANA_TIME_ZONE}". The ${IANA_TIME_ZONE} may only be a valid string from IANA time zone database. For example, `CRON_TZ=America/New_York 1 * * * *`, or `TZ=America/New_York 1 * * * *`. This field is required for RECURRING tasks.
    startTime : str, default is Undefined, optional
        Optional. The first run of the task will be after this time. If not specified, the task will run shortly after being submitted if ON_DEMAND and based on the schedule if RECURRING.
    $type : str, default is Undefined, optional
        Required. Immutable. Trigger type of the user-specified Task.
    """


    disabled?: bool

    maxRetries?: int

    schedule?: str

    startTime?: str

    $type?: str


schema DataplexCnrmCloudGoogleComV1alpha1DataplexTaskStatus:
    r"""
    DataplexTaskStatus defines the config connector machine state of DataplexTask

    Attributes
    ----------
    conditions : [DataplexCnrmCloudGoogleComV1alpha1DataplexTaskStatusConditionsItems0], default is Undefined, optional
        Conditions represent the latest available observations of the object's current state.
    externalRef : str, default is Undefined, optional
        A unique specifier for the DataplexTask resource in GCP.
    observedGeneration : int, default is Undefined, optional
        ObservedGeneration is the generation of the resource that was most recently observed by the Config Connector controller. If this is equal to metadata.generation, then that means that the current reported status reflects the most recent desired state of the resource.
    observedState : DataplexCnrmCloudGoogleComV1alpha1DataplexTaskStatusObservedState, default is Undefined, optional
        observed state
    """


    conditions?: [DataplexCnrmCloudGoogleComV1alpha1DataplexTaskStatusConditionsItems0]

    externalRef?: str

    observedGeneration?: int

    observedState?: DataplexCnrmCloudGoogleComV1alpha1DataplexTaskStatusObservedState


schema DataplexCnrmCloudGoogleComV1alpha1DataplexTaskStatusConditionsItems0:
    r"""
    dataplex cnrm cloud google com v1alpha1 dataplex task status conditions items0

    Attributes
    ----------
    lastTransitionTime : str, default is Undefined, optional
        Last time the condition transitioned from one status to another.
    message : str, default is Undefined, optional
        Human-readable message indicating details about last transition.
    reason : str, default is Undefined, optional
        Unique, one-word, CamelCase reason for the condition's last transition.
    status : str, default is Undefined, optional
        Status is the status of the condition. Can be True, False, Unknown.
    $type : str, default is Undefined, optional
        Type is the type of the condition.
    """


    lastTransitionTime?: str

    message?: str

    reason?: str

    status?: str

    $type?: str


schema DataplexCnrmCloudGoogleComV1alpha1DataplexTaskStatusObservedState:
    r"""
    ObservedState is the state of the resource as most recently observed in GCP.

    Attributes
    ----------
    createTime : str, default is Undefined, optional
        Output only. The time when the task was created.
    executionStatus : DataplexCnrmCloudGoogleComV1alpha1DataplexTaskStatusObservedStateExecutionStatus, default is Undefined, optional
        execution status
    state : str, default is Undefined, optional
        Output only. Current state of the task.
    uid : str, default is Undefined, optional
        Output only. System generated globally unique ID for the task. This ID will be different if the task is deleted and re-created with the same name.
    updateTime : str, default is Undefined, optional
        Output only. The time when the task was last updated.
    """


    createTime?: str

    executionStatus?: DataplexCnrmCloudGoogleComV1alpha1DataplexTaskStatusObservedStateExecutionStatus

    state?: str

    uid?: str

    updateTime?: str


schema DataplexCnrmCloudGoogleComV1alpha1DataplexTaskStatusObservedStateExecutionStatus:
    r"""
     Status of the task execution (e.g. Jobs).

    Attributes
    ----------
    latestJob : DataplexCnrmCloudGoogleComV1alpha1DataplexTaskStatusObservedStateExecutionStatusLatestJob, default is Undefined, optional
        latest job
    updateTime : str, default is Undefined, optional
        Output only. Last update time of the status.
    """


    latestJob?: DataplexCnrmCloudGoogleComV1alpha1DataplexTaskStatusObservedStateExecutionStatusLatestJob

    updateTime?: str


schema DataplexCnrmCloudGoogleComV1alpha1DataplexTaskStatusObservedStateExecutionStatusLatestJob:
    r"""
    Output only. latest job execution

    Attributes
    ----------
    endTime : str, default is Undefined, optional
        Output only. The time when the job ended.
    executionSpec : DataplexCnrmCloudGoogleComV1alpha1DataplexTaskStatusObservedStateExecutionStatusLatestJobExecutionSpec, default is Undefined, optional
        execution spec
    labels : {str:str}, default is Undefined, optional
        Output only. User-defined labels for the task.
    message : str, default is Undefined, optional
        Output only. Additional information about the current state.
    name : str, default is Undefined, optional
        Output only. The relative resource name of the job, of the form: `projects/{project_number}/locations/{location_id}/lakes/{lake_id}/tasks/{task_id}/jobs/{job_id}`.
    retryCount : int, default is Undefined, optional
        Output only. The number of times the job has been retried (excluding the initial attempt).
    service : str, default is Undefined, optional
        Output only. The underlying service running a job.
    serviceJob : str, default is Undefined, optional
        Output only. The full resource name for the job run under a particular service.
    startTime : str, default is Undefined, optional
        Output only. The time when the job was started.
    state : str, default is Undefined, optional
        Output only. Execution state for the job.
    trigger : str, default is Undefined, optional
        Output only. Job execution trigger.
    uid : str, default is Undefined, optional
        Output only. System generated globally unique ID for the job.
    """


    endTime?: str

    executionSpec?: DataplexCnrmCloudGoogleComV1alpha1DataplexTaskStatusObservedStateExecutionStatusLatestJobExecutionSpec

    labels?: {str:str}

    message?: str

    name?: str

    retryCount?: int

    service?: str

    serviceJob?: str

    startTime?: str

    state?: str

    trigger?: str

    uid?: str


schema DataplexCnrmCloudGoogleComV1alpha1DataplexTaskStatusObservedStateExecutionStatusLatestJobExecutionSpec:
    r"""
    Output only. Spec related to how a task is executed.

    Attributes
    ----------
    args : {str:str}, default is Undefined, optional
        The arguments to pass to the task. The args can use placeholders of the format ${placeholder} as part of key/value string. These will be interpolated before passing the args to the driver. Currently supported placeholders: - ${task_id} - ${job_time} To pass positional args, set the key as TASK_ARGS. The value should be a comma-separated string of all the positional arguments. To use a delimiter other than comma, refer to https://cloud.google.com/sdk/gcloud/reference/topic/escaping. In case of other keys being present in the args, then TASK_ARGS will be passed as the last argument.
    kmsKey : str, default is Undefined, optional
        The Cloud KMS key to use for encryption, of the form: `projects/{project_number}/locations/{location_id}/keyRings/{key-ring-name}/cryptoKeys/{key-name}`.
    maxJobExecutionLifetime : str, default is Undefined, optional
        The maximum duration after which the job execution is expired.
    project : str, default is Undefined, optional
        The project in which jobs are run. By default, the project containing the Lake is used. If a project is provided, the [ExecutionSpec.service_account][google.cloud.dataplex.v1.Task.ExecutionSpec.service_account] must belong to this project.
    serviceAccount : str, default is Undefined, required
        Service account to use to execute a task. If not provided, the default Compute service account for the project is used.
    """


    args?: {str:str}

    kmsKey?: str

    maxJobExecutionLifetime?: str

    project?: str

    serviceAccount: str


